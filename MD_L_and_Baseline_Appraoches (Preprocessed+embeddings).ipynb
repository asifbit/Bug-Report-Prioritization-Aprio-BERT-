{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_hfSHe0bPT3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9iXWpG2bBoj",
    "outputId": "b52e2b86-56e0-462d-de67-2c304c300b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8kQFusSbssw"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('/content/drive/MyDrive/Mobile Prioritazitation/Final_dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJebcY5fjuJG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "df['sentiment'] = labelencoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "zZUkMnPNE3Dh",
    "outputId": "3cab3582-c57a-4949-c80d-9c48daced261"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sentiment_categories = [1, 2, 3, 4, 5]\n",
    "\n",
    "ax=sns.countplot(x='sentiment', data=df)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.0f'),\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha = 'center', va = 'center',\n",
    "                xytext = (0, 6),\n",
    "                textcoords = 'offset points')\n",
    "# Setting x-tick labels to start from 1\n",
    "ax.set_xticklabels(sentiment_categories)\n",
    "# Adding x and y titles\n",
    "plt.xlabel('Priority')\n",
    "plt.ylabel('No. of Reviews')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6Tplv7ARrfR"
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'column1' and 'column2' are the column names you want to join\n",
    "df['review'] = df['title'].fillna('') + ' ' + df['body'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeNI8gguqT2k"
   },
   "outputs": [],
   "source": [
    "def preprocess_reviews(df, review_column, preprocessed_column):\n",
    "    # Convert text to lowercase\n",
    "    df[preprocessed_column] = df[review_column].str.lower()\n",
    "\n",
    "    # Replace NaN values with an empty string\n",
    "    df[preprocessed_column].fillna('', inplace=True)\n",
    "\n",
    "    # Remove numbers\n",
    "    df[preprocessed_column] = df[preprocessed_column].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "    # Remove punctuation\n",
    "    df[preprocessed_column] = df[preprocessed_column].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "    # Tokenize text\n",
    "    df[preprocessed_column] = df[preprocessed_column].apply(word_tokenize)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df[preprocessed_column] = df[preprocessed_column].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df[preprocessed_column] = df[preprocessed_column].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    df[preprocessed_column] = df[preprocessed_column].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = preprocess_reviews(df, 'review', 'preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YW0uLavsxME"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df.to_csv('/content/drive/MyDrive/Mobile Prioritazitation/preprocessed_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKcgG5i9tH0K"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Mobile Prioritazitation/preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "TF2ehCG4qYhS",
    "outputId": "64fd3d0a-a898-4c20-a922-e356c1997c2e"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlCnYqTr9E-8"
   },
   "outputs": [],
   "source": [
    "# # Preprocess the text data\n",
    "# text_data = df['preprocessed']  # Replace 'text_column' with the name of the column containing the text data\n",
    "# # text_data = df['review']  # Replace 'text_column' with the name of the column containing the text data\n",
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(text_data)\n",
    "\n",
    "# # Split the dataset into features (X) and labels (y)\n",
    "# y = df['star']  # Replace 'target_column' with the actual name of your target column\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Adjust the test_size and random_state as desired\n",
    "\n",
    "# # Create an SVM classifier\n",
    "# classifier = SVC(kernel='linear')\n",
    "\n",
    "# # Train the classifier on the training data\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = classifier.predict(X_test)\n",
    "\n",
    "# # Evaluate the accuracy of the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cM5tF6bGHQDw"
   },
   "outputs": [],
   "source": [
    "# # Print classification report and confusion matrix\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Calculate and print accuracy, precision, recall, and f1-score\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "# print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUyxj4Y9lMyp"
   },
   "source": [
    "# M/DL Models using Bert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFb6bh0VHhtA",
    "outputId": "65492f08-f5bc-4ced-d19f-acd310c94abb"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQKmo-9GvwoG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAWRGo9oxQw_"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856,
     "referenced_widgets": [
      "2199bd3714de4ba389c6f3bd7724af2b",
      "1250d5511d5f413290506ad4a1a69425",
      "f6ae444e311044b390f3a0a8afc84b5e",
      "f4314088bad643b693af5078ad81658b",
      "60a19c2b3bb8445e812195b0beea257f",
      "e485998712ee4c34a5d3f04285709080",
      "115e1e33b5394f19a08701d99005458a",
      "a1e25cd2d84540ed967834f9ef54bef8",
      "50c1d227af9c4bf0b547853765946f30",
      "adddd57bf9f2456f8b8adfb29219fdee",
      "397fb414396940af93940478e77336fd",
      "37799b15c4e34c04bbe60df2ccb429d7",
      "84ff9b9d2f024ffdbf142905ebbbf5a6",
      "c96aecdf9d1b466aaf8cad1661465c71",
      "fd63dd951a2d4a91b13a6da9f92a4cc4",
      "bca3a777a6cb4f49a3b2d779c1df5342",
      "107997c5cdb94b1cad9c8e2c2960328b",
      "40425cd491834bf794a47d7a7d3c9b32",
      "694c0046e0a94d5fbe02103589331598",
      "9e79052d5612436d9a7ae657c8438402",
      "230a0eaaaffa45a8a428cbbaa66a3b52",
      "7094f2613f804536961634e0cc44f3d9",
      "3ee39823560c4f4fbb520d3e7d24f678",
      "407b30f5f1e842039ae7a2cbc8befe4e",
      "e52d3b623c2e4715ae00532b9d3b2ee7",
      "1ed683c18f584d0e9ac0f7f2ab6581a1",
      "e10f7e9234de45339b620ba592476fde",
      "90bf44e21b074e9a8bb586062978e5fb",
      "b7f9e6d19dba4064b598b7c2a6994b40",
      "e374d2af4f624551b27b4982d628f2a4",
      "25005957e87e4debaed621767fbc28f0",
      "a54be4a586254a959299d7aa9968add5",
      "fe0e8ef446fb4bc98ea1ca3404a987b9",
      "8bb1be2cf8294c20b3e40824349923bd",
      "395ae5003b3e46af8535587daaa66e01",
      "7ebba1993ab3442fb375342cccc37ab2",
      "0a8d243be2d24038b49d54ebdc9cdbbc",
      "7a23a146e73e4b3aad74ba65fbbc539e",
      "04e2abfdd0e849dba131bdab5c581c58",
      "71704f87a8d54ec6a8fad42028c437af",
      "ed82d2a690ed4f9ea800beaa574d8a3d",
      "cd2ecd6bf48f4a3498af1ade7cdfc904",
      "9c26db928f4345ffa09d6e8fa8a8512b",
      "09ed9f8364d44d69b6c677e90ce4e286"
     ]
    },
    "id": "pYFa4c99xeI9",
    "outputId": "71180f95-64e6-428d-9f54-bd66a19fd76b"
   },
   "outputs": [],
   "source": [
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2dbJc91xhlU"
   },
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEszPAGt7Mgk"
   },
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    return [' '.join(sample) for sample in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gH2DyhVywrCg",
    "outputId": "0fa005d1-13ab-4ca9-8e49-5ae32d5dd181"
   },
   "outputs": [],
   "source": [
    "# Define batch size and create data loader\n",
    "batch_size = 64\n",
    "dataset = MyDataset(df['review'])\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, collate_fn=my_collate_fn)\n",
    "\n",
    "\n",
    "# Generate embeddings for each batch\n",
    "embeddings = []\n",
    "model.eval()\n",
    "i = 1\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        # Tokenize batch\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate embeddings\n",
    "        print(\"batch \")\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        mean_pooling = torch.mean(last_hidden_states, dim=1)\n",
    "        embeddings.append(mean_pooling.cpu())\n",
    "\n",
    "# Concatenate embeddings from each batch\n",
    "embeddings = torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axsS1auPe7XS"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/MP_df_embeddings_.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(embeddings, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqZpB8NUfPbs"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/MP_df_embeddings_.pickle\", \"rb\") as scores:\n",
    "   embeddings = pickle.load(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsuFGbQ1PsoB",
    "outputId": "7f6b5ae7-c641-4ec4-a818-b52194d3369b"
   },
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDp9msGwO8N6"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['sentiment'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Create an SVM model and fit it to the training data\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rDwXiUSPboQ"
   },
   "source": [
    "# Multinomial Naive Bays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asSM0FJ8Oeh1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['sentiment'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Binning the embeddings\n",
    "threshold = 0.5\n",
    "X_train_bin = np.where(X_train > threshold, 1, 0)\n",
    "X_test_bin = np.where(X_test > threshold, 1, 0)\n",
    "\n",
    "# Train the MNB model\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_bin, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = mnb.predict(X_test_bin)\n",
    "\n",
    "# Print classification report and accuracy score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Calculate and print accuracy, precision, recall, and f1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8GMdsteQiQM",
    "outputId": "40a59f63-bc84-4c2f-f905-974038990efb"
   },
   "outputs": [],
   "source": [
    "# Calculate and print accuracy, precision, recall, and f1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-KtaTyGPeMr"
   },
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_VIsaj3M7tw"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['sentiment'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model and fit it to the training data\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-po3ow0RSDV",
    "outputId": "70c2170c-4735-4e7c-fc50-0ea3209cec41"
   },
   "outputs": [],
   "source": [
    "# Calculate and print accuracy, precision, recall, and f1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ni-GUptP6RE"
   },
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xom8CJQyP243",
    "outputId": "eebf0191-79b1-402c-b7e4-61e9e540c733"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['sentiment'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Create a Random Forest model and fit it to the training data\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate and print accuracy, precision, recall, and f1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf5zdRAMk0WH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYSi36dMsnvn"
   },
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xN4fLqWDsm_Z",
    "outputId": "bab240e4-b8d9-43de-f594-41a5180d187b"
   },
   "outputs": [],
   "source": [
    "# # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['sentiment'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Define the boosting ensemble model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=10, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob_gb = gb_model.predict_proba(X_test.reshape((X_test.shape[0], -1)))\n",
    "y_pred_gb = np.round(y_pred_prob_gb[:, 1]).astype('int')\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tm0esL26GwZf",
    "outputId": "af162443-4b25-47c3-88dd-0089e7aebcb3"
   },
   "outputs": [],
   "source": [
    "# Calculate and print accuracy, precision, recall, and f1-score\n",
    "print(\"GBM.....\")\n",
    "accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_gb, average='weighted')\n",
    "print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SNsEnjx8hRZ",
    "outputId": "013ae375-d569-4818-a889-fde5d07e7619"
   },
   "outputs": [],
   "source": [
    "# Calculate count of each label\n",
    "unique_labels, label_counts = np.unique(df['star'], return_counts=True)\n",
    "\n",
    "# Print results\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(f\"Label {label}: {count} instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGZb5xrIwGfm"
   },
   "source": [
    "# LSTM on Ramdom Splition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prE0buX7pvjg",
    "outputId": "0b73fe1d-28a9-4849-dcb0-501614b6617e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['sentiment'].values, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "# Reshape the input data\n",
    "X_train = X_train[:, np.newaxis, :]\n",
    "X_test = X_test[:, np.newaxis, :]\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "# Set the parameters for the LSTM model\n",
    "input_size = X_train.shape[2]  # Number of features in the input (embedding size)\n",
    "hidden_size = 128  # Number of LSTM units\n",
    "output_size = 5  # Number of classes (adjust this based on your actual number of classes)\n",
    "\n",
    "\n",
    "\n",
    "# ... (previous code) ...\n",
    "\n",
    "# Define the LSTM model with an additional LSTM layer and dropout\n",
    "class ImprovedLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ImprovedLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Create an instance of the Improved LSTM model\n",
    "improved_model = ImprovedLSTMModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(improved_model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train.long())\n",
    "test_dataset = TensorDataset(X_test, y_test.long())\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    improved_model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = improved_model(inputs.float())\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluate the improved model on the test set\n",
    "improved_model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = improved_model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        true_labels.extend(targets.tolist())\n",
    "\n",
    "# Convert predictions and true labels to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = 100 * accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='macro')\n",
    "recall = recall_score(true_labels, predictions, average='macro')\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}%\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4eBSKQorMEO",
    "outputId": "e6ba0a69-d8ad-4650-f591-755df031db7d"
   },
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='macro')\n",
    "recall = recall_score(true_labels, predictions, average='macro')\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "print(f\"accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IloxVY1wVs8N"
   },
   "source": [
    "# Simple Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTkB2NL89sL3"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['sentiment'].values, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5hg2fAdshXI",
    "outputId": "0c4e67a7-2ea3-4b82-b8e8-b41b2f18709d"
   },
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "# Define the Neural Network model\n",
    "class SimpleNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Set the parameters for the neural network model\n",
    "input_size = X_train.shape[1]  # Number of features in the input (embedding size)\n",
    "hidden_size = 128  # Number of units in the hidden layer\n",
    "output_size = 10  # Number of classes (adjust this based on your actual number of classes)\n",
    "\n",
    "# Create an instance of the Neural Network model\n",
    "model = SimpleNNModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train.long())\n",
    "test_dataset = TensorDataset(X_test, y_test.long())\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        true_labels.extend(targets.tolist())\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "# Convert predictions and true labels to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "precision = precision_score(true_labels, predictions, average='macro')\n",
    "recall = recall_score(true_labels, predictions, average='macro')\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xsds8EmCCzC_"
   },
   "source": [
    "# Simle CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_wR7R9kvf14"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['sentiment'].values, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7dm6eomvyOj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already imported the required libraries and created 'X_train', 'X_test', 'y_train', and 'y_test'.\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "class AdvancedCNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(AdvancedCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(256 * (X_train.shape[-1] // 8), 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Set the parameters for the CNN model\n",
    "input_channels = 1  # Number of channels in the input data (since it's one-dimensional)\n",
    "num_classes = len(set(y_train.tolist()))  # Number of classes (adjust based on your actual number of classes)\n",
    "\n",
    "# Create an instance of the Advanced CNN model\n",
    "model = AdvancedCNNModel(input_channels, num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train.unsqueeze(1), y_train.long())  # Add an extra dimension for the channel\n",
    "test_dataset = TensorDataset(X_test.unsqueeze(1), y_test.long())\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        true_labels.extend(targets.tolist())\n",
    "\n",
    "# Convert predictions and true labels to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = 100 * accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='macro')\n",
    "recall = recall_score(true_labels, predictions, average='macro')\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqWdLaQKtymN"
   },
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tjj85-MwLhD",
    "outputId": "f7b9bd5e-e771-41b1-9906-f8406390b95f"
   },
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwzlYbo6wHkJ"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split data into training and test sets (assuming 'embeddings' is a NumPy array)\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['sentiment'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Multiclass classification\n",
    "    num_class=len(set(y_train)),  # Number of classes\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,  # Number of trees (boosting rounds)\n",
    "    max_depth=5,  # Maximum tree depth\n",
    "    subsample=0.8,  # Subsample ratio of the training instances\n",
    "    colsample_bytree=0.8,  # Subsample ratio of features for building each tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = 100 * accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVdarFl_56jZ"
   },
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwEHwZkj59Kl",
    "outputId": "9e2b8051-7e3c-4237-803e-0b95522ae9b2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split data into training and test sets (assuming 'embeddings' is a NumPy array)\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['sentiment'], test_size=0.20, random_state=42)\n",
    "# Create a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6bCzgcDuRh2"
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vN-dcV479iFn",
    "outputId": "822bd95f-f320-4f37-e9e1-1b926cf50259"
   },
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdgxVtBT-aTG",
    "outputId": "01b553df-c73e-4bbc-cee0-0af205fdfe36"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'embeddings' is a torch.Tensor \n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['sentiment'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors using the recommended approach\n",
    "X_train = torch.tensor(X_train).clone().detach()\n",
    "X_test = torch.tensor(X_test).clone().detach()\n",
    "y_train = torch.tensor(y_train.values).clone().detach()  # Convert to tensor and use .values to get the underlying numpy array\n",
    "y_test = torch.tensor(y_test.values).clone().detach()  # Convert to tensor and use .values to get the underlying numpy array\n",
    "\n",
    "# Set the parameters for the RNN model\n",
    "input_size = X_train.shape[1]  # Number of features in the input (embedding size)\n",
    "hidden_size = 128  # Number of units in the hidden layer\n",
    "output_size = len(set(y_train.tolist()))  # Number of classes (adjust based on your actual number of classes)\n",
    "\n",
    "# Define the RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x[:, np.newaxis, :], h0)  # Add a new dimension to the input tensor\n",
    "        out = self.fc(out[:, -1, :])  # Take the last time step's output for classification\n",
    "        return out\n",
    "\n",
    "# Create an instance of the RNN model\n",
    "rnn_model = RNNModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train.long())\n",
    "test_dataset = TensorDataset(X_test, y_test.long())\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Train the model\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    rnn_model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn_model(inputs.float())\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluate the RNN model on the test set\n",
    "rnn_model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = rnn_model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        true_labels.extend(targets.tolist())\n",
    "\n",
    "# Convert predictions and true labels to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = 100 * accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='macro')\n",
    "recall = recall_score(true_labels, predictions, average='macro')\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}%\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8iaUJwGaD-g"
   },
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mym8PcLUZ6_4",
    "outputId": "f27e7724-f823-4431-84fd-25e0f7abe766"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming 'embeddings' is a torch.Tensor\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['sentiment'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Create an instance of DecisionTreeClassifier as the base estimator\n",
    "base_estimator = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Create the AdaBoostClassifier with the base estimator\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the AdaBoost model\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = adaboost_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = 100 * accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}%\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLNET \n",
    "\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer\n",
    "\n",
    "# Prepare data from the loaded df\n",
    "texts = df['review'].tolist()\n",
    "labels = df['sentiment'].tolist()\n",
    "\n",
    "print(f\"Total samples: {len(texts)}\")\n",
    "\n",
    "# Split data (using same split as BERT for fair comparison)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_texts)}\")\n",
    "print(f\"Validation samples: {len(val_texts)}\")\n",
    "\n",
    "# Tokenize with XLNet\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "print(\"\\nTokenizing text data with XLNet...\")\n",
    "train_encodings = xlnet_tokenizer(train_texts, truncation=True, padding=True, max_length=256)\n",
    "val_encodings = xlnet_tokenizer(val_texts, truncation=True, padding=True, max_length=256)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\nBatch size: {batch_size}\")\n",
    "print(f\"Training batches: {len(train_dataloader)}\")\n",
    "\n",
    "# Load XLNet model\n",
    "num_labels = len(set(labels))\n",
    "xlnet_model = XLNetForSequenceClassification.from_pretrained(\n",
    "    'xlnet-base-cased',\n",
    "    num_labels=num_labels,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "xlnet_model.to(device)\n",
    "\n",
    "print(f\"\\nModel loaded: XLNet-Base\")\n",
    "print(f\"Number of classes: {num_labels}\")\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "epochs = 16\n",
    "optimizer = AdamW(xlnet_model.parameters(), lr=2e-5, eps=1e-8)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining setup:\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Learning rate: {2e-5}\")\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STARTING XLNET TRAINING\")\n",
    "print('='*60)\n",
    "\n",
    "xlnet_losses = []\n",
    "xlnet_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "xlnet_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    total_batches = len(train_dataloader)\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        xlnet_model.zero_grad()\n",
    "        outputs = xlnet_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_correct += torch.sum(torch.argmax(logits, dim=1) == labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(xlnet_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    avg_loss = epoch_loss / total_batches\n",
    "    avg_acc = epoch_correct.float() / (total_batches * batch_size)\n",
    "    \n",
    "    xlnet_losses.append(avg_loss)\n",
    "    xlnet_accuracies.append(avg_acc.item())\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.4f}')\n",
    "\n",
    "xlnet_training_time = time.time() - start_time\n",
    "print(f\"\\nXLNet Training Time: {xlnet_training_time:.2f} seconds\")\n",
    "\n",
    "# Evaluation\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EVALUATING XLNET MODEL\")\n",
    "print('='*60)\n",
    "\n",
    "xlnet_model.eval()\n",
    "xlnet_predictions = []\n",
    "xlnet_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = xlnet_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        xlnet_predictions.extend(preds.cpu().numpy())\n",
    "        xlnet_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate all metrics\n",
    "xlnet_predictions = np.array(xlnet_predictions)\n",
    "xlnet_true_labels = np.array(xlnet_true_labels)\n",
    "\n",
    "print(f\"\\nEvaluation on {len(xlnet_true_labels)} samples\")\n",
    "\n",
    "# Weighted metrics\n",
    "xlnet_weighted_precision = precision_score(xlnet_true_labels, xlnet_predictions, average='weighted')\n",
    "xlnet_weighted_recall = recall_score(xlnet_true_labels, xlnet_predictions, average='weighted')\n",
    "xlnet_weighted_f1 = f1_score(xlnet_true_labels, xlnet_predictions, average='weighted')\n",
    "\n",
    "# Macro metrics\n",
    "xlnet_macro_precision = precision_score(xlnet_true_labels, xlnet_predictions, average='macro')\n",
    "xlnet_macro_recall = recall_score(xlnet_true_labels, xlnet_predictions, average='macro')\n",
    "xlnet_macro_f1 = f1_score(xlnet_true_labels, xlnet_predictions, average='macro')\n",
    "\n",
    "# Micro metrics\n",
    "xlnet_micro_precision = precision_score(xlnet_true_labels, xlnet_predictions, average='micro')\n",
    "xlnet_micro_recall = recall_score(xlnet_true_labels, xlnet_predictions, average='micro')\n",
    "xlnet_micro_f1 = f1_score(xlnet_true_labels, xlnet_predictions, average='micro')\n",
    "\n",
    "xlnet_accuracy = accuracy_score(xlnet_true_labels, xlnet_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XLNET FINE-TUNING RESULTS (16 EPOCHS)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: preprocessed_df.csv\")\n",
    "print(f\"\\nOverall Accuracy: {xlnet_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nWeighted Averages:\")\n",
    "print(f\"  Precision: {xlnet_weighted_precision:.4f}\")\n",
    "print(f\"  Recall:    {xlnet_weighted_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {xlnet_weighted_f1:.4f}\")\n",
    "\n",
    "print(\"\\nMacro Averages:\")\n",
    "print(f\"  Precision: {xlnet_macro_precision:.4f}\")\n",
    "print(f\"  Recall:    {xlnet_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {xlnet_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nMicro Averages:\")\n",
    "print(f\"  Precision: {xlnet_micro_precision:.4f}\")\n",
    "print(f\"  Recall:    {xlnet_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {xlnet_micro_f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "xlnet_confusion = confusion_matrix(xlnet_true_labels, xlnet_predictions)\n",
    "print(f\"\\nConfusion Matrix:\\n{xlnet_confusion}\")\n",
    "\n",
    "# Save XLNet results\n",
    "xlnet_results = {\n",
    "    'accuracy': xlnet_accuracy,\n",
    "    'weighted': {'precision': xlnet_weighted_precision, 'recall': xlnet_weighted_recall, 'f1': xlnet_weighted_f1},\n",
    "    'macro': {'precision': xlnet_macro_precision, 'recall': xlnet_macro_recall, 'f1': xlnet_macro_f1},\n",
    "    'micro': {'precision': xlnet_micro_precision, 'recall': xlnet_micro_recall, 'f1': xlnet_micro_f1},\n",
    "    'confusion_matrix': xlnet_confusion,\n",
    "    'training_time': xlnet_training_time,\n",
    "    'epochs': epochs,\n",
    "    'losses': xlnet_losses,\n",
    "    'accuracies': xlnet_accuracies,\n",
    "    'dataset_info': {\n",
    "        'source': 'preprocessed_df.csv',\n",
    "        'total_samples': len(texts),\n",
    "        'train_samples': len(train_texts),\n",
    "        'val_samples': len(val_texts),\n",
    "        'num_classes': num_labels\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROBERTA \n",
    "\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "# Prepare data from the loaded df\n",
    "texts = df['review'].tolist()\n",
    "labels = df['sentiment'].tolist()\n",
    "\n",
    "print(f\"Total samples: {len(texts)}\")\n",
    "\n",
    "# Split data (using same split for consistency)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_texts)}\")\n",
    "print(f\"Validation samples: {len(val_texts)}\")\n",
    "\n",
    "# Tokenize with RoBERTa\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "print(\"\\nTokenizing text data with RoBERTa...\")\n",
    "train_encodings = roberta_tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = roberta_tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\nBatch size: {batch_size}\")\n",
    "print(f\"Training batches: {len(train_dataloader)}\")\n",
    "\n",
    "# Load RoBERTa model\n",
    "num_labels = len(set(labels))\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained(\n",
    "    'roberta-base',\n",
    "    num_labels=num_labels,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "roberta_model.to(device)\n",
    "\n",
    "print(f\"\\nModel loaded: RoBERTa-Base\")\n",
    "print(f\"Number of classes: {num_labels}\")\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "epochs = 16\n",
    "optimizer = AdamW(roberta_model.parameters(), lr=2e-5, eps=1e-8)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining setup:\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Learning rate: {2e-5}\")\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STARTING ROBERTA TRAINING\")\n",
    "print('='*60)\n",
    "\n",
    "roberta_losses = []\n",
    "roberta_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "roberta_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    total_batches = len(train_dataloader)\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        roberta_model.zero_grad()\n",
    "        outputs = roberta_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_correct += torch.sum(torch.argmax(logits, dim=1) == labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(roberta_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    avg_loss = epoch_loss / total_batches\n",
    "    avg_acc = epoch_correct.float() / (total_batches * batch_size)\n",
    "    \n",
    "    roberta_losses.append(avg_loss)\n",
    "    roberta_accuracies.append(avg_acc.item())\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.4f}')\n",
    "\n",
    "roberta_training_time = time.time() - start_time\n",
    "print(f\"\\nRoBERTa Training Time: {roberta_training_time:.2f} seconds\")\n",
    "\n",
    "# Evaluation\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EVALUATING ROBERTA MODEL\")\n",
    "print('='*60)\n",
    "\n",
    "roberta_model.eval()\n",
    "roberta_predictions = []\n",
    "roberta_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = roberta_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        roberta_predictions.extend(preds.cpu().numpy())\n",
    "        roberta_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate all metrics\n",
    "roberta_predictions = np.array(roberta_predictions)\n",
    "roberta_true_labels = np.array(roberta_true_labels)\n",
    "\n",
    "print(f\"\\nEvaluation on {len(roberta_true_labels)} samples\")\n",
    "\n",
    "# Weighted metrics\n",
    "roberta_weighted_precision = precision_score(roberta_true_labels, roberta_predictions, average='weighted')\n",
    "roberta_weighted_recall = recall_score(roberta_true_labels, roberta_predictions, average='weighted')\n",
    "roberta_weighted_f1 = f1_score(roberta_true_labels, roberta_predictions, average='weighted')\n",
    "\n",
    "# Macro metrics\n",
    "roberta_macro_precision = precision_score(roberta_true_labels, roberta_predictions, average='macro')\n",
    "roberta_macro_recall = recall_score(roberta_true_labels, roberta_predictions, average='macro')\n",
    "roberta_macro_f1 = f1_score(roberta_true_labels, roberta_predictions, average='macro')\n",
    "\n",
    "# Micro metrics\n",
    "roberta_micro_precision = precision_score(roberta_true_labels, roberta_predictions, average='micro')\n",
    "roberta_micro_recall = recall_score(roberta_true_labels, roberta_predictions, average='micro')\n",
    "roberta_micro_f1 = f1_score(roberta_true_labels, roberta_predictions, average='micro')\n",
    "\n",
    "roberta_accuracy = accuracy_score(roberta_true_labels, roberta_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ROBERTA FINE-TUNING RESULTS (16 EPOCHS)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: preprocessed_df.csv\")\n",
    "print(f\"\\nOverall Accuracy: {roberta_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nWeighted Averages:\")\n",
    "print(f\"  Precision: {roberta_weighted_precision:.4f}\")\n",
    "print(f\"  Recall:    {roberta_weighted_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {roberta_weighted_f1:.4f}\")\n",
    "\n",
    "print(\"\\nMacro Averages:\")\n",
    "print(f\"  Precision: {roberta_macro_precision:.4f}\")\n",
    "print(f\"  Recall:    {roberta_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {roberta_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nMicro Averages:\")\n",
    "print(f\"  Precision: {roberta_micro_precision:.4f}\")\n",
    "print(f\"  Recall:    {roberta_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {roberta_micro_f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "roberta_confusion = confusion_matrix(roberta_true_labels, roberta_predictions)\n",
    "print(f\"\\nConfusion Matrix:\\n{roberta_confusion}\")\n",
    "\n",
    "# Save RoBERTa results\n",
    "roberta_results = {\n",
    "    'accuracy': roberta_accuracy,\n",
    "    'weighted': {'precision': roberta_weighted_precision, 'recall': roberta_weighted_recall, 'f1': roberta_weighted_f1},\n",
    "    'macro': {'precision': roberta_macro_precision, 'recall': roberta_macro_recall, 'f1': roberta_macro_f1},\n",
    "    'micro': {'precision': roberta_micro_precision, 'recall': roberta_micro_recall, 'f1': roberta_micro_f1},\n",
    "    'confusion_matrix': roberta_confusion,\n",
    "    'training_time': roberta_training_time,\n",
    "    'epochs': epochs,\n",
    "    'losses': roberta_losses,\n",
    "    'accuracies': roberta_accuracies,\n",
    "    'dataset_info': {\n",
    "        'source': 'preprocessed_df.csv',\n",
    "        'total_samples': len(texts),\n",
    "        'train_samples': len(train_texts),\n",
    "        'val_samples': len(val_texts),\n",
    "        'num_classes': num_labels\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04e2abfdd0e849dba131bdab5c581c58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09ed9f8364d44d69b6c677e90ce4e286": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a8d243be2d24038b49d54ebdc9cdbbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c26db928f4345ffa09d6e8fa8a8512b",
      "placeholder": "",
      "style": "IPY_MODEL_09ed9f8364d44d69b6c677e90ce4e286",
      "value": " 440M/440M [00:02&lt;00:00, 179MB/s]"
     }
    },
    "107997c5cdb94b1cad9c8e2c2960328b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "115e1e33b5394f19a08701d99005458a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1250d5511d5f413290506ad4a1a69425": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e485998712ee4c34a5d3f04285709080",
      "placeholder": "",
      "style": "IPY_MODEL_115e1e33b5394f19a08701d99005458a",
      "value": "Downloading ()solve/main/vocab.txt: 100%"
     }
    },
    "1ed683c18f584d0e9ac0f7f2ab6581a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a54be4a586254a959299d7aa9968add5",
      "placeholder": "",
      "style": "IPY_MODEL_fe0e8ef446fb4bc98ea1ca3404a987b9",
      "value": " 570/570 [00:00&lt;00:00, 22.1kB/s]"
     }
    },
    "2199bd3714de4ba389c6f3bd7724af2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1250d5511d5f413290506ad4a1a69425",
       "IPY_MODEL_f6ae444e311044b390f3a0a8afc84b5e",
       "IPY_MODEL_f4314088bad643b693af5078ad81658b"
      ],
      "layout": "IPY_MODEL_60a19c2b3bb8445e812195b0beea257f"
     }
    },
    "230a0eaaaffa45a8a428cbbaa66a3b52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25005957e87e4debaed621767fbc28f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37799b15c4e34c04bbe60df2ccb429d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84ff9b9d2f024ffdbf142905ebbbf5a6",
       "IPY_MODEL_c96aecdf9d1b466aaf8cad1661465c71",
       "IPY_MODEL_fd63dd951a2d4a91b13a6da9f92a4cc4"
      ],
      "layout": "IPY_MODEL_bca3a777a6cb4f49a3b2d779c1df5342"
     }
    },
    "395ae5003b3e46af8535587daaa66e01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04e2abfdd0e849dba131bdab5c581c58",
      "placeholder": "",
      "style": "IPY_MODEL_71704f87a8d54ec6a8fad42028c437af",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "397fb414396940af93940478e77336fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ee39823560c4f4fbb520d3e7d24f678": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_407b30f5f1e842039ae7a2cbc8befe4e",
       "IPY_MODEL_e52d3b623c2e4715ae00532b9d3b2ee7",
       "IPY_MODEL_1ed683c18f584d0e9ac0f7f2ab6581a1"
      ],
      "layout": "IPY_MODEL_e10f7e9234de45339b620ba592476fde"
     }
    },
    "40425cd491834bf794a47d7a7d3c9b32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407b30f5f1e842039ae7a2cbc8befe4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90bf44e21b074e9a8bb586062978e5fb",
      "placeholder": "",
      "style": "IPY_MODEL_b7f9e6d19dba4064b598b7c2a6994b40",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "50c1d227af9c4bf0b547853765946f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "60a19c2b3bb8445e812195b0beea257f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "694c0046e0a94d5fbe02103589331598": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7094f2613f804536961634e0cc44f3d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71704f87a8d54ec6a8fad42028c437af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a23a146e73e4b3aad74ba65fbbc539e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ebba1993ab3442fb375342cccc37ab2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed82d2a690ed4f9ea800beaa574d8a3d",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd2ecd6bf48f4a3498af1ade7cdfc904",
      "value": 440449768
     }
    },
    "84ff9b9d2f024ffdbf142905ebbbf5a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_107997c5cdb94b1cad9c8e2c2960328b",
      "placeholder": "",
      "style": "IPY_MODEL_40425cd491834bf794a47d7a7d3c9b32",
      "value": "Downloading ()okenizer_config.json: 100%"
     }
    },
    "8bb1be2cf8294c20b3e40824349923bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_395ae5003b3e46af8535587daaa66e01",
       "IPY_MODEL_7ebba1993ab3442fb375342cccc37ab2",
       "IPY_MODEL_0a8d243be2d24038b49d54ebdc9cdbbc"
      ],
      "layout": "IPY_MODEL_7a23a146e73e4b3aad74ba65fbbc539e"
     }
    },
    "90bf44e21b074e9a8bb586062978e5fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c26db928f4345ffa09d6e8fa8a8512b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e79052d5612436d9a7ae657c8438402": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1e25cd2d84540ed967834f9ef54bef8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a54be4a586254a959299d7aa9968add5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adddd57bf9f2456f8b8adfb29219fdee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7f9e6d19dba4064b598b7c2a6994b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bca3a777a6cb4f49a3b2d779c1df5342": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96aecdf9d1b466aaf8cad1661465c71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_694c0046e0a94d5fbe02103589331598",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e79052d5612436d9a7ae657c8438402",
      "value": 28
     }
    },
    "cd2ecd6bf48f4a3498af1ade7cdfc904": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e10f7e9234de45339b620ba592476fde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e374d2af4f624551b27b4982d628f2a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e485998712ee4c34a5d3f04285709080": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e52d3b623c2e4715ae00532b9d3b2ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e374d2af4f624551b27b4982d628f2a4",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_25005957e87e4debaed621767fbc28f0",
      "value": 570
     }
    },
    "ed82d2a690ed4f9ea800beaa574d8a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4314088bad643b693af5078ad81658b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adddd57bf9f2456f8b8adfb29219fdee",
      "placeholder": "",
      "style": "IPY_MODEL_397fb414396940af93940478e77336fd",
      "value": " 232k/232k [00:00&lt;00:00, 4.98MB/s]"
     }
    },
    "f6ae444e311044b390f3a0a8afc84b5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1e25cd2d84540ed967834f9ef54bef8",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50c1d227af9c4bf0b547853765946f30",
      "value": 231508
     }
    },
    "fd63dd951a2d4a91b13a6da9f92a4cc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_230a0eaaaffa45a8a428cbbaa66a3b52",
      "placeholder": "",
      "style": "IPY_MODEL_7094f2613f804536961634e0cc44f3d9",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.01kB/s]"
     }
    },
    "fe0e8ef446fb4bc98ea1ca3404a987b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
