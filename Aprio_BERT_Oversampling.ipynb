{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9iXWpG2bBoj",
    "outputId": "f05758a2-67cd-4d7c-d3ef-5cc056e7141f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_hfSHe0bPT3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8kQFusSbssw",
    "outputId": "fb92a8e1-4a3d-4596-facb-08c56ea92a8c"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('/content/drive/MyDrive/Mobile Prioritazitation/Final_dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJebcY5fjuJG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "df['sentiment'] = labelencoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "zZUkMnPNE3Dh",
    "outputId": "3cab3582-c57a-4949-c80d-9c48daced261"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sentiment_categories = [1, 2, 3, 4, 5]\n",
    "\n",
    "ax=sns.countplot(x='sentiment', data=df)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.0f'),\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha = 'center', va = 'center',\n",
    "                xytext = (0, 6),\n",
    "                textcoords = 'offset points')\n",
    "# Setting x-tick labels to start from 1\n",
    "ax.set_xticklabels(sentiment_categories)\n",
    "# Adding x and y titles\n",
    "plt.xlabel('Priority')\n",
    "plt.ylabel('No. of Reviews')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-g4oKN9nVY2",
    "outputId": "476f8d75-e6b6-4374-ff8a-422f507b273d"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDNiDEK3IyT4",
    "outputId": "34583cc6-00c4-4532-8072-c4a9621c0eb7"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df.drop('sentiment', axis=1)\n",
    "y = df['sentiment']\n",
    "\n",
    "# Perform oversampling\n",
    "oversample = RandomOverSampler(sampling_strategy='not majority')\n",
    "X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# Combine the oversampled X and y into a single dataframe\n",
    "os_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "# Check the shape and class distribution of the new dataframe\n",
    "print(os_df.shape)\n",
    "print(os_df['sentiment'].value_counts())\n",
    "\n",
    "df = os_df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "tvESjCHIng25",
    "outputId": "438b59e4-43f4-43a3-992e-c05c48bf8938"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sentiment_categories = [1, 2, 3, 4, 5]\n",
    "\n",
    "ax=sns.countplot(x='sentiment', data=df)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.0f'),\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha = 'center', va = 'center',\n",
    "                xytext = (0, 6),\n",
    "                textcoords = 'offset points')\n",
    "# Setting x-tick labels to start from 1\n",
    "ax.set_xticklabels(sentiment_categories)\n",
    "# Adding x and y titles\n",
    "plt.xlabel('Priority Level')\n",
    "plt.ylabel('No. of Reviews')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "chEsSsOjbxsC",
    "outputId": "4933cd95-8969-412f-bf69-f2a274ea5961"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6u4r7_8ob4lD"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "learning_rate = 2e-5\n",
    "batch_size = 16\n",
    "epochs = 16\n",
    "num_labels = 5\n",
    "attention_heads = 12\n",
    "gradient_accumulation_steps = 16\n",
    "hidden_size = 768\n",
    "hidden_layers = 12\n",
    "max_seq_length = 256\n",
    "num_params = 110_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6Z_LaDFfUZ7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4z1oQ7hmo80Z"
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'column1' and 'column2' are the column names you want to join\n",
    "df['review'] = df['title'].fillna('') + ' ' + df['body'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CM6K4fUFiRCG",
    "outputId": "43177522-d415-45c6-e5e6-39d1fdfa3f59"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the input data using the BERT tokenizer for the training set\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "for _, row in train_df.iterrows():\n",
    "    sentence = row['review']\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_seq_length,\n",
    "                        pad_to_max_length=True,\n",
    "                        return_attention_mask=True,\n",
    "                        return_tensors='pt'\n",
    "                   )\n",
    "    print(\"iteration\")\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])\n",
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim=0)\n",
    "\n",
    "# Convert labels to a 1D numpy array for the training set\n",
    "train_labels = np.array(train_df['sentiment'])\n",
    "# Convert labels to a tensor for the training set\n",
    "train_labels = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kca8K7OA25rZ",
    "outputId": "5b6f7d4d-6af7-4ec2-99d5-49029b3b7878"
   },
   "outputs": [],
   "source": [
    "unique_labels = torch.unique(train_labels)\n",
    "label_counts = torch.bincount(train_labels)\n",
    "for label in unique_labels:\n",
    "    count = label_counts[label]\n",
    "    print(f\"Label {label}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axsS1auPe7XS"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/train_input_ids_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(train_input_ids, scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/train_attention_masks_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(train_attention_masks, scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/train_labels_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(train_labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqZpB8NUfPbs"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/train_input_ids_os.pickle\", \"rb\") as scores:\n",
    "   train_input_ids = pickle.load(scores)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/train_attention_masks_os.pickle\", \"rb\") as scores:\n",
    "   train_attention_masks= pickle.load(scores)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/train_labels_os.pickle\", \"rb\") as scores:\n",
    "   train_labels = pickle.load(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Q3V49Mj0_rU",
    "outputId": "138bfc14-54e7-42cb-c64f-cd60b4ea1fde"
   },
   "outputs": [],
   "source": [
    "print(train_input_ids.shape)\n",
    "print(train_attention_masks.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUj_4rGKB6fL",
    "outputId": "6f2ae137-ac23-4beb-f809-6dd37de768e5"
   },
   "outputs": [],
   "source": [
    "# Create the training dataset and data loader\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "print(train_dataset)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDuUNtalKsyb"
   },
   "outputs": [],
   "source": [
    "# Tokenize the input data using the BERT tokenizer for testing set\n",
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPxS7_iFhoYN"
   },
   "outputs": [],
   "source": [
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "for _, row in test_df.iterrows():\n",
    "    sentence = row['review']\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_seq_length,\n",
    "                        pad_to_max_length=True,\n",
    "                        return_attention_mask=True,\n",
    "                        return_tensors='pt'\n",
    "                   )\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
    "\n",
    "# Convert labels to a 1D numpy array for the training set\n",
    "test_labels = np.array(test_df['sentiment'])\n",
    "# Convert labels to a tensor for the training set\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qNuGHWzLi4B"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/test_input_ids_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(test_input_ids, scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/test_attention_masks_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(test_attention_masks, scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/test_labels_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(test_labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlKB9E-rLi4C"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/test_input_ids_os.pickle\", \"rb\") as scores:\n",
    "   test_input_ids = pickle.load(scores)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/test_attention_masks_os.pickle\", \"rb\") as scores:\n",
    "   test_attention_masks = pickle.load(scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/test_labels_os.pickle\", \"rb\") as scores:\n",
    "  test_labels = pickle.load(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rTarRfYuMugI",
    "outputId": "0fafb33d-d710-44e9-bdff-a4bbe9c5037a"
   },
   "outputs": [],
   "source": [
    "print(test_input_ids.shape)\n",
    "print(test_attention_masks.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikFA5PhrCG12"
   },
   "outputs": [],
   "source": [
    "# Create the testing dataset and data loader\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PtH_W38RgDDQ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers.optimization import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6xc7bfMl5z4"
   },
   "outputs": [],
   "source": [
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "for _, row in df.iterrows():\n",
    "    sentence = row['review']\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_seq_length,\n",
    "                        pad_to_max_length=True,\n",
    "                        return_attention_mask=True,\n",
    "                        return_tensors='pt'\n",
    "                   )\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "import numpy as np\n",
    "\n",
    "# Convert labels to a 1D numpy array for the training set\n",
    "val_labels = np.array(df['sentiment'])\n",
    "# Convert labels to a tensor for the training set\n",
    "val_labels = torch.tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m60_iR-TNord"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/val_input_ids_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(val_input_ids, scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/val_attention_masks_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(val_attention_masks, scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/val_labels_os.pickle\", \"wb\") as scores:\n",
    "    pickle.dump(val_labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HNcapG_Norf"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/val_input_ids_os.pickle\", \"rb\") as scores:\n",
    "   val_input_ids = pickle.load(scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/val_attention_masks_os.pickle\", \"rb\") as scores:\n",
    "   val_attention_masks = pickle.load(scores)\n",
    "with open(\"/content/drive/MyDrive/Mobile Prioritazitation/val_labels_os.pickle\", \"rb\") as scores:\n",
    "  val_labels = pickle.load(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzybQ_TcNKpo",
    "outputId": "28a2c950-91e3-416e-ea2f-93de113e4ac9"
   },
   "outputs": [],
   "source": [
    "print(val_input_ids.shape)\n",
    "print(val_attention_masks.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzWvWBdECUcH"
   },
   "outputs": [],
   "source": [
    "# Create the validation dataset and data loader\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgKaNAyaltFy"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "f7c36f0ef9664d73bfb4c2d8c495af4d",
      "957f4e97b6d54556941905e7f8c6b444",
      "884f707e57c24706a3b69050d8fbe66f",
      "0b4a64e703884ae9ab178ee9e55dd9f0",
      "0d318f2076694c10ae63b351a07f0125",
      "a28c93d40603413f93a48585e49bd061",
      "01170e80303446849d7376ae86cad4f4",
      "999365fdcdc84fdfaaf0e422bbc91890",
      "46ff123758cf4a8c831ea05c61f13340",
      "1f12bec7b10748798b0489911e31536a",
      "8f8fb070ba464e819dcefa5ff792701c"
     ]
    },
    "id": "T84JLl-0jD9F",
    "outputId": "4f4dd508-7618-4e99-acda-a1030858d654"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "# Move the model to the GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer and the learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader)*epochs)\n",
    "\n",
    "# Set the number of epochs, the training and validation steps, and the loss function\n",
    "epochs = 10\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "train_steps = len(train_dataloader)\n",
    "eval_steps = len(val_dataloader)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VybZuXm9jJqQ",
    "outputId": "9f4b498a-8437-4793-ab21-a52f25225001"
   },
   "outputs": [],
   "source": [
    "x = list(range(1, epochs+1))\n",
    "losses = []  # Track loss values\n",
    "accuracies = []  # Track accuracy values\n",
    "# Initialize the timer for training\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_correct += torch.sum(torch.argmax(logits, dim=1) == labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if (step + 1) % train_steps == 0:\n",
    "            epoch_loss /= train_steps\n",
    "            epoch_acc = epoch_correct / (train_steps * batch_size)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{step+1}/{train_steps}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "            # Calculate epoch loss and accuracy\n",
    "            epoch_loss /= train_steps\n",
    "            epoch_acc = epoch_correct / (train_steps * batch_size)\n",
    "\n",
    "            # Store the metric values\n",
    "            losses.append(epoch_loss)\n",
    "            accuracies.append(epoch_acc)\n",
    "            epoch_loss = 0\n",
    "            epoch_correct = 0\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time: {:.4f} seconds\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "bgQWIHB1ArjV",
    "outputId": "4c560bc1-6f68-4e22-f789-956066faf2bf"
   },
   "outputs": [],
   "source": [
    "# Initialize the figure and axes\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "# Update the plots\n",
    "ax[0].plot(x[:len(losses)], losses,  color=\"red\", label=\"Loss\")\n",
    "ax[1].plot(x[:len(accuracies)], [acc.cpu().detach().item() for acc in accuracies],  color=\"blue\", label=\"Accuracy\")\n",
    "\n",
    "\n",
    "# Set plot labels and titles\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\" Training Loss\")\n",
    "# ax[0].set_title(\"Training Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"Training Accuracy\")\n",
    "# ax[1].set_title(\"Training Accuracy\")\n",
    "ax[1].legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "ovCauR4KEOq4",
    "outputId": "1504de2c-ff9b-464d-9219-1aa949615ec8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have two lists 'losses' and 'accuracies' containing the loss and accuracy values, respectively.\n",
    "\n",
    "x = range(1, len(losses) + 1)  # Assuming 'x' represents the epochs\n",
    "\n",
    "# Initialize the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Update the plots\n",
    "ax.plot(x[:len(losses)], losses,  color=\"red\", label=\"Loss\")\n",
    "ax.plot(x[:len(accuracies)], [acc.cpu().detach().item() for acc in accuracies],  color=\"blue\", label=\"Accuracy\")\n",
    "\n",
    "# Set plot labels and titles\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Training Accuracy and Loss Value\")\n",
    "# ax.set_title(\"Training Loss and Accuracy\")\n",
    "\n",
    "# Add a legend to differentiate loss and accuracy lines\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRMCiYpVjSRj"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "eval_loss = 0\n",
    "eval_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNoX5uxYHb0L"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Initialize lists to store the accuracy and loss on each iteration\n",
    "# iteration_accuracy = []\n",
    "# iteration_loss = []\n",
    "\n",
    "# # Evaluate the model on the test dataset\n",
    "# model.eval()\n",
    "# predictions = []\n",
    "# true_labels = []\n",
    "\n",
    "# # Initialize the timer for testing\n",
    "# start_time = time.time()\n",
    "# # Evaluation of Model\n",
    "# with torch.no_grad():\n",
    "#     for batch in val_dataloader:\n",
    "#         input_ids = batch[0].to(device)\n",
    "#         attention_mask = batch[1].to(device)\n",
    "#         labels = batch[2].to(device)\n",
    "\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         logits = outputs.logits\n",
    "\n",
    "#         eval_correct = torch.sum(torch.argmax(logits, dim=1) == labels)\n",
    "#         iteration_accuracy.append(eval_correct.item() / len(labels))\n",
    "#         iteration_loss.append(loss.item())\n",
    "\n",
    "#         predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "#         true_labels.extend(labels.tolist())\n",
    "\n",
    "# # Calculate the testing time\n",
    "# testing_time = time.time() - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9shS5DjoH48r",
    "outputId": "1955dcbc-71cd-48b1-869f-4da1d5e38ee9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store accuracy and loss values\n",
    "iteration_accuracy = []\n",
    "iteration_loss = []\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "eval_loss = 0\n",
    "eval_correct = 0\n",
    "# Initialize the timer for testing\n",
    "start_time = time.time()\n",
    "\n",
    "# Evaluation of Model\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        eval_loss += loss.item()\n",
    "        eval_correct += torch.sum(torch.argmax(logits, dim=1) == labels)\n",
    "\n",
    "        predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "\n",
    "        # Store accuracy and loss values\n",
    "        iteration_accuracy.append(accuracy_score(true_labels, predictions))\n",
    "        iteration_loss.append(eval_loss / (step + 1))\n",
    "\n",
    "# Calculate the testing time\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Compute the accuracy, precision, recall, and F1 score\n",
    "acc = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "\n",
    "# Print the testing time\n",
    "print(\"Testing Time: {:.2f} seconds\".format(testing_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "7d85bJnu8Zjs",
    "outputId": "269ee174-8f3a-43f5-f590-c74f6c6cfebe"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have two lists 'iteration_accuracy' and 'iteration_loss' containing the accuracy and loss values on each iteration, respectively.\n",
    "\n",
    "iterations = range(1, len(iteration_accuracy) + 1)\n",
    "\n",
    "# Initialize the figure and axes\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "\n",
    "# Update the accuracy subplot\n",
    "line_accuracy, = ax[0].plot(iterations, iteration_accuracy, label='Testing Accuracy')\n",
    "ax[0].set_xlabel(\"Iteration\")\n",
    "ax[0].set_ylabel(\"Testing Accuracy\")\n",
    "# ax[0].set_title(\"Testing Accuracy on Each Iteration\")\n",
    "\n",
    "# Update the loss subplot\n",
    "line_loss, = ax[1].plot(iterations, iteration_loss, color='red', label='Testing Loss')\n",
    "ax[1].set_xlabel(\"Iteration\")\n",
    "ax[1].set_ylabel(\"Testing Loss\")\n",
    "# ax[1].set_title(\"Testing Loss on Each Iteration\")\n",
    "\n",
    "# Add legend to both subplots\n",
    "ax[0].legend(handles=[line_accuracy], loc='upper right')\n",
    "ax[1].legend(handles=[line_loss], loc='upper left')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "SsSzJjpNCel_",
    "outputId": "0f8d540d-13fa-4751-d0af-5d7045467ddc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have two lists 'iteration_accuracy' and 'iteration_loss' containing the accuracy and loss values on each iteration, respectively.\n",
    "\n",
    "iterations = range(1, len(iteration_accuracy) + 1)\n",
    "\n",
    "# Initialize the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Update the accuracy subplot\n",
    "ax.plot(iterations, iteration_accuracy, label='Testing Accuracy', color='blue')\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "# ax.set_ylabel(\"Accuracy\")\n",
    "# ax.set_title(\"Accuracy and Loss on Each Iteration\")\n",
    "\n",
    "# Update the loss subplot\n",
    "ax.plot(iterations, iteration_loss, label='Testing Loss', color='red')\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Accuracy and Loss Value\")\n",
    "\n",
    "# Add a legend to differentiate accuracy and loss lines\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OV_yFRcF5bS",
    "outputId": "28d48ae1-d297-474c-8fb5-14201e50b651"
   },
   "outputs": [],
   "source": [
    "# Print the metrics\n",
    "# print(f'Test Loss: {eval_loss:.4f}, Test Accuracy: {eval_acc:.4f}')\n",
    "print(f'Test Accuracy: {acc:.4f}')\n",
    "print(f'Test Precision: {precision:.4f}')\n",
    "print(f'Test Recall: {recall:.4f}')\n",
    "print(f'Test F1 Score: {f1:.4f}')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_pred and y_true are assumed to be numpy arrays or lists\n",
    "confusion = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "mY3udRSEUY_3",
    "outputId": "20d677fd-aec2-4627-ae58-9d6c335dc710"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Print classification report for ensemble model\n",
    "target_names = ['1 Star', '2 Star', '3 Star','4 Star','5 Star']\n",
    "print(classification_report(true_labels, predictions, target_names=target_names))\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# corr, linewidths=.3, cmap=\"RdBu\", annot=True, fmt=\"\"\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='g', linewidths=.2, cmap='RdBu')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZHxE7vNbUMT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGO6m1Ss1vHF",
    "outputId": "03b791cf-9e7d-40c0-c5a1-66f96230b3f4"
   },
   "outputs": [],
   "source": [
    "# Macro metrics\n",
    "precision_macro = precision_score(true_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(true_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "# Micro metrics\n",
    "precision_micro = precision_score(true_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(true_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(true_labels, predictions, average='micro')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {acc}')\n",
    "print('Macro Metrics:')\n",
    "print(f'Precision: {precision_macro}')\n",
    "print(f'Recall: {recall_macro}')\n",
    "print(f'F1-Score: {f1_macro}')\n",
    "\n",
    "print('Micro Metrics:')\n",
    "print(f'Precision: {precision_micro}')\n",
    "print(f'Recall: {recall_micro}')\n",
    "print(f'F1-Score: {f1_micro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVqLbVC8RYrB",
    "outputId": "3a549579-e897-4bf6-9585-acbb3e14b27b"
   },
   "outputs": [],
   "source": [
    "# Assuming y_test contains the true labels and y_pred contains the predicted labels\n",
    "\n",
    "# Calculate classification report\n",
    "target_names = ['1', '2', '3', '4', '5']\n",
    "report = classification_report(true_labels, predictions, target_names=target_names, output_dict=True)\n",
    "\n",
    "# Calculate accuracy separately\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "# Print precision, recall, f1-score, and accuracy for each class\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        class_accuracy = metrics[\"support\"] * metrics[\"recall\"]\n",
    "        print(f'Class: {label}')\n",
    "        print(f'Class Accuracy: {class_accuracy}')\n",
    "        print(f'Precision: {metrics[\"precision\"]}')\n",
    "        print(f'Recall: {metrics[\"recall\"]}')\n",
    "        print(f'F1-score: {metrics[\"f1-score\"]}')\n",
    "        print(f'Support: {metrics[\"support\"]}')\n",
    "\n",
    "\n",
    "# Print overall accuracy\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01170e80303446849d7376ae86cad4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b4a64e703884ae9ab178ee9e55dd9f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f12bec7b10748798b0489911e31536a",
      "placeholder": "​",
      "style": "IPY_MODEL_8f8fb070ba464e819dcefa5ff792701c",
      "value": " 440M/440M [00:05&lt;00:00, 248MB/s]"
     }
    },
    "0d318f2076694c10ae63b351a07f0125": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f12bec7b10748798b0489911e31536a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46ff123758cf4a8c831ea05c61f13340": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "884f707e57c24706a3b69050d8fbe66f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_999365fdcdc84fdfaaf0e422bbc91890",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46ff123758cf4a8c831ea05c61f13340",
      "value": 440449768
     }
    },
    "8f8fb070ba464e819dcefa5ff792701c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "957f4e97b6d54556941905e7f8c6b444": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a28c93d40603413f93a48585e49bd061",
      "placeholder": "​",
      "style": "IPY_MODEL_01170e80303446849d7376ae86cad4f4",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "999365fdcdc84fdfaaf0e422bbc91890": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a28c93d40603413f93a48585e49bd061": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7c36f0ef9664d73bfb4c2d8c495af4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_957f4e97b6d54556941905e7f8c6b444",
       "IPY_MODEL_884f707e57c24706a3b69050d8fbe66f",
       "IPY_MODEL_0b4a64e703884ae9ab178ee9e55dd9f0"
      ],
      "layout": "IPY_MODEL_0d318f2076694c10ae63b351a07f0125"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
